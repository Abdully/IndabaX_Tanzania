{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGvdlOsS2r7b"
   },
   "source": [
    "# PytzMLS2018: Lab 3: Deep learning for computer vision\n",
    "\n",
    "<center>**Anthony Faustine (sambaiga@gmail.com)**</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jSLreCQ2r7e"
   },
   "source": [
    "## Import all necessary libries and modules we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bFOaxlqL2r7g"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import copy\n",
    "from ploting import *\n",
    "import PIL\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1080\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCk78zIZ2r7o"
   },
   "source": [
    "## Part 1. Convolutional Neural Network\n",
    "\n",
    "**Learning goal**: How to implement a CNN using PyTorch. In this lab we will train a CNN using PyTorch. \n",
    "\n",
    "\n",
    "**Task**: Build CNN image classifier to recognize handwritten digits using the  FashionMNIST dataset.  FashionMNIST contains contains Zalando’s article images with 60,000 images in the training set and 10,000 in the test set. Each sample is a 28×20 grayscale image with a label from 10 classes: t-shirt, trouser, pullver, dress, coat, sandal, shirt, sneaker, bag and ankle boot.\n",
    "\n",
    " This dataset base designed to be used as a drop-in replacement of the original MNST dataset.\n",
    "\n",
    "** Procedure**\n",
    "\n",
    "1. Load the training and test datasets using DataLoader\n",
    "2. Define a Feedforwad Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpVl21Zs2r7p"
   },
   "source": [
    "### 1.1 Load dataset\n",
    "\n",
    "We will use DataLoader and TensorDataset (from torch.utils.data) for convinience in data handling. You can create your custom dataset class by inheriting Dataset with some required member functions.\n",
    "\n",
    "The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors and normalise the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1945,
     "status": "ok",
     "timestamp": 1519729237513,
     "user": {
      "displayName": "Anthony Faustine",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105111460447012653451"
     },
     "user_tz": -60
    },
    "id": "t_0LwfD32r7r",
    "outputId": "3976170f-c38c-4a9e-89f2-95ebfe35efaf"
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='../data/fashionmnist', train=True, download=True, transform=transform)\n",
    "                          \n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='../data/fashionmnist', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72QRHbOU2r7w"
   },
   "source": [
    "### 1.1.1 Make iteratable data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HwDWOMzH2r7y"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qv1oNGs12r72"
   },
   "source": [
    "### 1.1.2  Visualize train dataset\n",
    "\n",
    "\n",
    "Let's inspect a few examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=6)\n",
    "fig, axs = plt.subplots(2,5, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.25, wspace=.1)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    axs[i].imshow(train_dataset.train_data[i].numpy(), cmap='gray', interpolation='none')\n",
    "    axs[i].set_title('%s' % classes[train_dataset.train_labels[i]], fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tmhRpd82r8C"
   },
   "source": [
    "### 1.2. Define  CNN model\n",
    "\n",
    "In this step we define CNN model in which a key module for constructing a convolutional net is nn.ConvXd. Although we use 2-dimensional convolution layer, parameters are almost same for all X-dimensional convolution layers. You need to specify the number of input channels (in_channels), the number of output channels (out_channels), the kernel (filter) size (kernel_size), stride size (stride), zero-padding (padding), and so forth as discussed in the tutorial.\n",
    "\n",
    "We will use 2 convolution layers with max pooling and they are followed by 2 fully-connected layers with RELU activation. We do not apply any activation at the output layer to use activation-combined loss function for a better numerical stability. The network is shown below:\n",
    "\n",
    "`conv(1)=>ReLU=>MaxPool=>Conv2=>ReLU=>MaxPool=>FC1=>FC2`\n",
    "\n",
    "\n",
    "\n",
    "**Conv1**:\n",
    "- in_channel (D) = 1 (since the image is Grey scale)\n",
    "- out_chabbel (K) = 10\n",
    "- Filter_size (F) = 5\n",
    "- Stride_size (S) = 1\n",
    "\n",
    "self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "\n",
    "**MaxPool**:\n",
    "- Filter size (F)=2\n",
    "- Stride (S)=2\n",
    "self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "**Conv2**:\n",
    "- in_channel (D) = 10 (output_channel of Conv1)\n",
    "- out_chabbel (K) = 20\n",
    "- Filter_size (F) = 5\n",
    "- Stride_size (S) = 1\n",
    "- self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "\n",
    "\n",
    "**Questions**\n",
    "1. What is the purpose of pooling layer?\n",
    "2. What is the output size of conv1 and conv2?\n",
    "3. What is the output size of MaxPool layer 1 and MaxPool layer 2?\n",
    "4. Show that the input dimension of FC1 is $4\\times 4\\times 20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "d2gZnEtT2r8E"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.fc1 = nn.Linear(20*4*4, 10)\n",
    "       \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out  = F.relu(self.conv1(x))\n",
    "        out  = self.pool(out)\n",
    "        out  = F.relu(self.conv2(out))\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1519383340811,
     "user": {
      "displayName": "Anthony Faustine",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105111460447012653451"
     },
     "user_tz": -60
    },
    "id": "itYARhtK2r8J",
    "outputId": "740fc260-979c-4acd-b05f-29d22cb87fb0"
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWc0esPq2r8Q"
   },
   "source": [
    "### 1.3. Define a Loss function and Optimizer¶\n",
    "\n",
    "Since this is multi-class classification we will use **Cross Entropy loss**. PyTorch provide **Cross Entropy loss**  loss function which combines a softmax layer and the **Cross Entropy loss** together and it is more numerically stable than using them separately. Thus it is why we didnt  apply softmax activation after the output layer while defining MLP model. See the last model definition above.\n",
    "\n",
    "We will use SGD with momentum as our optimizer. When we create an optimizer in PyTorch, we need to pass parameters that we want to optimize (train) as input arguments. We can retrieve all trainable parameters of the model by calling **model.parameters()**.\n",
    "\n",
    "**Questions**\n",
    "1. Write an expression of a softmax function.\n",
    "2. What are the advantage of using SGD with momentum in training neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "S8EMLCcW2r8R"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVUIzbIx2r8Z"
   },
   "source": [
    "### 1.4. Train the network\n",
    "Now, we need to train the model. For each full coverage of train dataset, we just need to do a forward pass computation with a mini-batch of dataset and a backward pass to compute gradients followed by a step of optimization. We need to do this for a reasonable number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cmIvbHHG2r8a"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, num_epochs):\n",
    "    \n",
    "    \n",
    "    total_loss = []\n",
    "    print(\"Start training\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        training_loss = []\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward pass to get output/logits\n",
    "            outputs = model(images)\n",
    "        \n",
    "            # Calculate Loss: softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        \n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "        \n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "            training_loss.append(loss.data[0])\n",
    "        \n",
    "            # print statistics\n",
    "            # print statistics\n",
    "           \n",
    "            if i %4000 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}'.format(\n",
    "                epoch+1, i * len(images), len(train_loader.dataset),\n",
    "                100. * i / len(train_loader), np.mean(training_loss)))\n",
    "             \n",
    "              \n",
    "        total_loss.append(np.mean(training_loss))     \n",
    "        \n",
    "       \n",
    "    return total_loss    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1822,
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 624460,
     "status": "ok",
     "timestamp": 1519384003124,
     "user": {
      "displayName": "Anthony Faustine",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105111460447012653451"
     },
     "user_tz": -60
    },
    "id": "dqOU4lhB2r8d",
    "outputId": "c04935fe-ec1c-462b-d32e-fea09061b359"
   },
   "outputs": [],
   "source": [
    "total_loss = train(model, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xjDVwaU2r8k"
   },
   "source": [
    "### 1.4.1 Visualize training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 421,
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1519384098717,
     "user": {
      "displayName": "Anthony Faustine",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105111460447012653451"
     },
     "user_tz": -60
    },
    "id": "p2CXLm4B2r8m",
    "outputId": "f796cc75-5b02-406b-9325-31e65d003dd3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(total_loss, label=\"rate={}\".format(learning_rate))\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HaGwtP4u2r8s"
   },
   "source": [
    "### 1.5 Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lDlVsc022r8u"
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    predictions=[]\n",
    "    ground_t=[]\n",
    "    \n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get predictions from the maximum value\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        predictions  += pred.numpy().tolist()\n",
    "        ground_t+= labels.data.numpy().tolist()\n",
    "        #correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        correct += torch.sum(pred == labels.data)\n",
    "    \n",
    "    print('')\n",
    "    predictions = np.array(predictions)\n",
    "    ground_t    = np.array(ground_t)   \n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        \n",
    "    print(\"Accuracy: {}%\".format(accuracy))\n",
    "    \n",
    "    return ground_t, predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 53,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1308,
     "status": "ok",
     "timestamp": 1519384119803,
     "user": {
      "displayName": "Anthony Faustine",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105111460447012653451"
     },
     "user_tz": -60
    },
    "id": "9ak2AZsL2r80",
    "outputId": "3a665201-4119-42d7-d8e9-f146af815bba"
   },
   "outputs": [],
   "source": [
    "ground_t, predictions = test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VGCvAKzn2r85"
   },
   "source": [
    "### 1.5.1 VIsualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1519384125389,
     "user": {
      "displayName": "Anthony Faustine",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105111460447012653451"
     },
     "user_tz": -60
    },
    "id": "m63kksLS2r85",
    "outputId": "58bd6f38-80dc-42a7-f4e6-7301e6225af7"
   },
   "outputs": [],
   "source": [
    "correct_indices = np.nonzero(predictions == ground_t)[0]\n",
    "incorrect_indices = np.nonzero(predictions != ground_t)[0]\n",
    "print()\n",
    "print(len(correct_indices),\" classified correctly\")\n",
    "print(len(incorrect_indices),\" classified incorrectly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4qJjJkN2r9C"
   },
   "source": [
    "#### 1.5.1.1 Visualize correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 159,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1519384176345,
     "user": {
      "displayName": "Anthony Faustine",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105111460447012653451"
     },
     "user_tz": -60
    },
    "id": "3G81g6SA2r9E",
    "outputId": "22c753de-24d0-4b52-f4ef-6b9ce934c6bf"
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,6))\n",
    "indices = np.random.permutation(correct_indices)\n",
    "figure_evaluation = plt.figure()\n",
    "\n",
    "# plot 9 correct predictions\n",
    "for i, correct in enumerate(indices[:9]):\n",
    "    plt.subplot(6,3,i+1)\n",
    "    plt.imshow(test_dataset.test_data[correct].numpy(),  cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Actual {}\".format(classes[predictions[correct]], classes[ground_t[correct]]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZlxEuTg2r9Q"
   },
   "source": [
    "#### 1.5.1.2 Visualize incorrect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 159,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1519384213557,
     "user": {
      "displayName": "Anthony Faustine",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105111460447012653451"
     },
     "user_tz": -60
    },
    "id": "_WrCzRH22r9R",
    "outputId": "1f9c890f-33f6-4242-b103-d59aa2efa0ec"
   },
   "outputs": [],
   "source": [
    "indices = np.random.permutation(incorrect_indices)\n",
    "figure_evaluation = plt.figure()\n",
    "\n",
    "# plot 9 correct predictions\n",
    "for i, correct in enumerate(indices[:9]):\n",
    "    plt.subplot(6,3,i+1)\n",
    "    plt.imshow(test_dataset.test_data[correct].numpy(), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Actual {}\".format(classes[predictions[correct]], classes[ground_t[correct]]))\n",
    "    plt.xticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task:\n",
    "1. What techniques can you use to improve the predictive accuracy?\n",
    "2. Modify the network or the training procedure to improve the performance.\n",
    "3. What is the maximum possible accuracy did you achive from step number 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fB0V0hgM2r_K"
   },
   "source": [
    "## Part 2 Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfK1jxf42r_L"
   },
   "source": [
    "**Transfer learning**  is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task.\n",
    "\n",
    "It is a popular approach in deep learning where pre-trained models are used as the starting point on computer vision and natural language processing tasks given the vast compute and time resources required to develop neural network models on these problems and from the huge jumps in skill that they provide on related problems.\n",
    "\n",
    "**Why Transfer Learning?**\n",
    "- In practice, very few people train an entire CNN from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.\n",
    "\n",
    "- Very Deep Networks are expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.For example, training ResNet18 for 30 epochs in 4 NVIDIA K80 GPU took us 3 days. Training ResNet152 for 120 epochs in the same GPUs takes 4 months.\n",
    "- Determining the topology/flavour/training method/hyper parameters for deep learning is a black art with not much theory to guide you.\n",
    "\n",
    "\"DON'T TRY TO BE AN HERO\" ~Andrej Karapathy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning Strategies:\n",
    "\n",
    "In general, there are two strategies to perform transfer learning,\n",
    "\n",
    " **Fine-tuning**: consists of using the pretrained network on the base dataset and train all layers in the target dataset. The startegy is useful when the new dataset is large and very different from the original dataset. Since you have large dataset, you can design your own network or use the existing ones. Train the network using random initialisations or use the pre-trained network weights as initialisers. The second one is generally preferred.\n",
    " \n",
    "If the new dataset is small but very different from the original dataset you will need  to extract the features from the earlier layer and train a classifier on top of that. To achieve this you will need to add a few FC layers and output layer, set the weights for earlier layers and freeze them and then train the network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extractor** \n",
    " \n",
    " - **Freeze all layer except the final one**: which consists of leaving all but the last layer frozen (the weights are not updated) and train the last layer. Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained. This strategy is useful if the new dataset is small and similar to original dataset.\n",
    " \n",
    "Pytorch Implementation\n",
    "\n",
    "```python\n",
    "for params in model_.parameters():\n",
    "    params.requires_grad = False \n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Freezing the first few layers**: In this case you will need to freeze the first few layers and train the network.This strategy is useful if the new dataset is larger and similar to original dataset. \n",
    "\n",
    "Pytorch implementation freezing the first 5 layers \n",
    "\n",
    "```python\n",
    "ct = 0\n",
    "for name, child in model.named_children():\n",
    "    ct += 1\n",
    "    if ct < 7:\n",
    "        for name2, params in child.named_parameters():\n",
    "        params.requires_grad = False         \n",
    "```            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 1 Transfer learning 1: Build a classifier for detecting ants and bees\n",
    "\n",
    "**Learning goal**: How to implement a Transfer learning using PyTorch.\n",
    "\n",
    "\n",
    "\n",
    "**Task**: Build CNN image classifier to classifiy ants and bees. The dataset have about 120 training images each for ants and bees. There are 75 validation images for each class. Usually, this is a very small dataset to generalize upon, if trained from scratch. Since we are using transfer learning, we should be able to generalize reasonably well.\n",
    "\n",
    "** Procedure**\n",
    "\n",
    "1. Download dataset and perform data augementation.\n",
    "2. Load and define models for transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Download dataset and perform data augementation\n",
    "\n",
    "Download the dataset from this [link](https://download.pytorch.org/tutorial/hymenoptera_data.zip). For this lab the data can be found in `../data/hymenoptera/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/hymenoptera/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data directory should contain train and valid directories. The train and val directory have subdirs for each class you wish to recognize (in this case, 'beens' and 'ants'). we can verify if these directory are present in the defined PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view sub-directory in valid folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(f'{PATH}val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view some files in this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(f'{PATH}val/bees')[:5]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(f'{PATH}val/bees/{files[0]}')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: \n",
    "- Visualize few images for ants in train directory\n",
    "- What is the size, mode and format of these image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augementation\n",
    "Data augmentation is a process where you make changes to existing images like adjusting the colors , flipping it horizontally or vertically , scaling , cropping and many more. Pytorch provides a very useful library called `torchvision.transforms` which provides a lot of methods which helps to apply data augmentation. transforms comes with a `compose` method which takes a list of transformation. The pre-trained models expect input  mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225]\n",
    "\n",
    "First we create a `transform` object that transform for train and test images:\n",
    "\n",
    "- For train images resize  image to 244 size by croping to random size and aspect ratioin order to ensure that the training runs quickly, horizontally flip the given image randomly with a given probability (default p=0.5) and transform to tesnsor and finalize normalize the image.\n",
    "\n",
    "- For valid images we resize  image to 256, crops at the center to 224, transform to tensor and finalize normalize the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(os.path.join(PATH, x),transform[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) \n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a few images after transformation\n",
    "\n",
    "Let’s visualize a few training images so as to understand the data augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(inp):\n",
    "    \n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    \n",
    "    return inp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inverse_transform(inp)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=10)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "beatify(fig_width=4)\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dataloaders['val']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "beatify(fig_width=4)\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Load and define models for transfer learning: Finetuning the convnet\n",
    "\n",
    "\n",
    "\n",
    "We will use a model called [**ResNet**](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035) from Microsoft which won the ImageNet competition in 2015. The ResNet model compromises of a bunch of ResNet blocks(Combination of convolution and identity block) and a fully connected layer. The model is trained on Imagenet dataset on 1000 categories , we will remove the last fully connected layer and add a new fully connected layer which outputs 2 categories which tells the probability of the image being Ant or Bee. For this problem we will use finetuning strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a pretrained model and reset final fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "print(model_resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Resnet18 here. If you have more computational power, feel free to swap it with Resnet50, Resnet100 or Resnet152. Since we are doing fine-tuning, or transfer learning we will use the pretrained net weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of feature from the final FC layer\n",
    "num_features = model_resnet18.fc.in_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since imagenet as 1000 classes , We need to change our last layer according to the number of classes we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define FC layer with two output category\n",
    "model_resnet18.fc = nn.Linear(num_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2.1 Define loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_rst18 = torch.optim.SGD(model_resnet18.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decaying  Learning rate\n",
    "Most of the times we start with a higher learning rate so that we can reduce the loss faster and then after a few epochs you would like to reduce it so that the learning becoming slower. `torch.optim.lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs. The `StepLR` function sets the learning rate of each parameter group to the initial lr decayed by gamma every step_size epochs. When last_epoch=-1, sets initial lr as lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "# Decay LR by a factor of 0.1 every 2 epochs\n",
    "scheduler_lr = lr_scheduler.StepLR(optimizer_rst18 , step_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if cuda availabe and change the model and criterion to cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_resnet18 = model_resnet18.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2.2 Training the model\n",
    "Now, let's write a general function to train a model. Here, we will illustrate. The function will Schedule the learning rate and save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=25):\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = fit_model(model_resnet18, criterion, optimizer_rst18,  scheduler_lr, dataloaders, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2.3 Visualize prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write a generic function to display predictions for a some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    \n",
    "    training_mode = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    \n",
    "\n",
    "    for i, data in enumerate(dataloaders['val']):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            plt.subplot(2, int(num_images/2), images_so_far)\n",
    "            plt.imshow(inverse_transform(inputs.cpu().data[j]))\n",
    "            plt.title('predicted: {}'.format(class_names[preds[j]]), fontsize=8)\n",
    "            plt.tight_layout()\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            #ax.axis('off')\n",
    "    \n",
    "            if images_so_far == num_images:\n",
    "                model.train(mode=training_mode)\n",
    "                return\n",
    "    model.train(mode=training_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=4)\n",
    "visualize_model(model_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Load and define models for transfer learning: ConvNet as fixed feature extractor\n",
    "\n",
    "\n",
    "Here, we need to freeze all the network except the final layer. We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward().\n",
    "\n",
    "You can read more about this in the documentation here <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet18_conv = models.resnet18(pretrained=True)\n",
    "for param in model_resnet18_conv.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of newly constructed modules have requires_grad=True by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature = model_resnet18_conv.fc.in_features\n",
    "model_resnet18_conv.fc = nn.Linear(num_feature, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3.1 Define loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_rst18_conv = torch.optim.SGD(model_resnet18_conv.fc.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "Observe that only parameters of final layer are being optimized as opoosed to before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define schedule\n",
    "scheduler_lr_conv = lr_scheduler.StepLR(optimizer_rst18_conv, step_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if Cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    model_resnet18_conv = model_resnet18_conv.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3.1 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best_conv = fit_model(model_resnet18_conv, criterion, optimizer_rst18_conv, scheduler_lr_conv, dataloaders, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatify(fig_width=4)\n",
    "visualize_model(model_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "1. How can you compare the two approaches above? \n",
    "2. What is the best score for each aproaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 2 Transfer learning 2:  VGG\n",
    "\n",
    "VGG model is one of the most studied Deep learning models for transfer learning is VGG. The model can be split into two kinds of logical blocks\n",
    "\n",
    " **Convolution blocks**: The pre-trained VGG model is trained on Image net data set over 1000 categories. The convolutional block contains multiple convolution layers. The initial layers contain low level features like lines , curves . The last convolutional layers in this block contain more complex kind of features of images like hand, leg , eyes and many more.The convolution layers exhibit 2 important properties.\n",
    " - The number of parameters required is far less compared to fully connected layer. For example a Convolution layer with $3 * 3 * 64$ size filters need only 576 parameters.\n",
    " - Convolution layers are computationally expensive and take longer to compute the output.\n",
    " \n",
    "**Fully Connected Block**: This block contains FC layers with dropouts. The number of parameters to learn in FC layers are huge but takes way less time to compute.\n",
    "\n",
    "So, we generally end up taking pre convoluted features from Convolution block of VGG model as it is and training only the last few layers of the VGG model which are generally from FC block.\n",
    "\n",
    "PyTorch's implementation of VGG is a module divided in two child\n",
    "``Sequential`` modules: ``features`` (containing convolution and pooling\n",
    "layers) and ``classifier`` (containing fully connected layers). We are\n",
    "just interested by ``features``:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Load and define models for transfer learning using VGG "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we have to import a pre-trained neural network.We\n",
    "are going to use a pretrained VGG network with 19 layers (VGG19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: \n",
    "\n",
    "1. Use VGG as feature extractor to build CNN classify for the above problem, compare your results with the resnet18 models.\n",
    "2. Fine tune VGG and build CNN classify for the above problem, compare your results with the resnet18 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task**:\n",
    "- Use transfer learning to develop CNN model to classify dog and cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [A Gentle Introduction to Transfer Learning for Deep Learning\n",
    "](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)\n",
    "- [Transfer Learning - Machine Learning's Next Frontier](http://ruder.io/transfer-learning/)\n",
    "- [Transfer](http://cs231n.github.io/transfer-learning/)\n",
    "- [Transfer learning using pytorch — Part 1](https://towardsdatascience.com/transfer-learning-using-pytorch-4c3475f4495)\n",
    "- [Transfer learning using pytorch — Part 2](https://towardsdatascience.com/transfer-learning-using-pytorch-part-2-9c5b18e15551)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "Deep learning for computer vision.ipynb",
   "provenance": [
    {
     "file_id": "1PTWBCnqX_PkuU61gI3R2O1u8meYQ-0__",
     "timestamp": 1519727183838
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
